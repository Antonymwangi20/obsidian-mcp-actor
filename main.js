/**
 * Refactored Apify Actor Entry Point
 * Uses service-oriented architecture with dependency injection
 * Reduced from 300+ lines to ~150 lines of clear, maintainable code
 */

import { Actor } from 'apify';
import fs from 'fs/promises';

// Import services
import { CheerioStrategy } from './lib/scraper/CheerioStrategy.js';
import { PlaywrightStrategy } from './lib/scraper/PlaywrightStrategy.js';
import { MemoryCache } from './lib/cache/MemoryCache.js';
import { NoteManager } from './lib/vault/NoteManager.js';
import { LinkManager } from './lib/vault/LinkManager.js';
import { MarkdownConverter } from './lib/processor/MarkdownConverter.js';
import { TagExtractor } from './lib/processor/TagExtractor.js';
import { loadTemplateConfig, loadVaultConfig } from './lib/helpers.js';

await Actor.main(async () => {
    // â”â” INPUT LOADING â”â”
    let input = await Actor.getInput();
    if (!input) {
        try {
            input = JSON.parse(await fs.readFile('./input.json', 'utf-8'));
            console.log('âœ“ Loaded input from input.json');
        } catch {
            input = {};
        }
    }

    // â”â” CONFIG MERGING â”â”
    const vaultConfig = input.vaultPath ? await loadVaultConfig(input.vaultPath) : {};
    const templateConfig = (input.templatePath && input.vaultPath)
        ? await loadTemplateConfig(input.vaultPath, input.templatePath)
        : {};

    const config = { ...vaultConfig, ...input, ...templateConfig };

    const {
        url,
        urls = [],
        vaultPath,
        noteName,
        folderPath = 'scraped',
        addMetadata = true,
        tags = [],
        autoTag = true,
        autoLink = true,
        bulkMode = false,
        updateExisting = false,
        usePlaywright = false,
        playwrightTimeout = 30,
        rateLimitDelay = 2000
    } = config;

    // â”â” VALIDATION â”â”
    if (!vaultPath || (bulkMode && urls.length === 0) || (!bulkMode && !url)) {
        throw new Error('Missing required config: vaultPath and (url or urls array)');
    }

    // â”â” SERVICE INITIALIZATION â”â”
    const cache = new MemoryCache({ maxSize: 100 });
    const noteManager = new NoteManager(vaultPath);
    const linkManager = new LinkManager(vaultPath);
    const markdownConverter = new MarkdownConverter({ addMetadata });
    const tagExtractor = new TagExtractor();

    const cheerioStrategy = new CheerioStrategy({
        timeout: playwrightTimeout * 1000,
        cache,
        maxRetries: 3
    });

    const playwrightStrategy = new PlaywrightStrategy({
        timeout: playwrightTimeout * 1000,
        cache,
        enableStealth: true,
        blockWebSockets: true
    });

    // â”â” METRICS TRACKING â”â”
    const metrics = {
        startTime: Date.now(),
        processed: 0,
        successful: 0,
        failed: 0,
        totalBytes: 0
    };

    // â”â” MAIN PROCESSING LOOP â”â”
    const urlsToProcess = bulkMode ? urls : [url];
    const results = await import('./lib/processor/ActorService.js').then(m => m.processUrls({
        ...config,
        urls: urlsToProcess
    }));

    // â”â” OUTPUT â”â”
    await Actor.pushData({
        success: results.every(r => r.success),
        results
    });

    console.log('âœ“ Done!');
});

/**
 * FEATURE 3: Scan vault for notes and extract tags
 */
async function scanVaultForNotes(vaultPath) {
    const notes = [];
    
    const scan = async (dir, relativePath = '') => {
        try {
            const items = await fs.readdir(dir);
            
            for (const item of items) {
                const fullPath = path.join(dir, item);
                const stats = await fs.stat(fullPath);
                const relPath = path.join(relativePath, item);
                
                if (stats.isDirectory() && !item.startsWith('.')) {
                    await scan(fullPath, relPath);
                } else if (item.endsWith('.md')) {
                    const content = await fs.readFile(fullPath, 'utf-8');
                    const tagsMatch = content.match(/tags:\s*\[(.*?)\]/);
                    const extractedTags = tagsMatch ? 
                        tagsMatch[1].split(',').map(t => t.trim().replace(/['"]/g, '')) : [];
                    
                    notes.push({
                        fileName: item.replace('.md', ''),
                        path: relPath,
                        tags: extractedTags
                    });
                }
            }
        } catch (error) {
            // Ignore directory scan errors
        }
    };
    
    try {
        await scan(vaultPath);
    } catch (error) {
        // Vault doesn't exist yet, return empty
    }
    
    return notes;
}

/**
 * Convert scraped data to Markdown with front-matter
 */
function convertToMarkdown(data, addMetadata, tags) {
    let markdown = '';

    // Add YAML front-matter
    if (addMetadata) {
        markdown += '---\n';
        markdown += `title: "${data.title.replace(/"/g, '\\"')}"\n`;
        markdown += `url: ${data.url}\n`;
        markdown += `scraped: ${new Date().toISOString()}\n`;
        if (tags.length > 0) {
            markdown += `tags: [${tags.join(', ')}]\n`;
        }
        if (data.metadata.description) {
            markdown += `description: "${data.metadata.description.replace(/"/g, '\\"')}"\n`;
        }
        if (data.metadata.author) {
            markdown += `author: "${data.metadata.author.replace(/"/g, '\\"')}"\n`;
        }
        markdown += '---\n\n';
    }

    // Add title
    markdown += `# ${data.title}\n\n`;

    // Add source link
    markdown += `> ðŸ”— Source: [${data.url}](${data.url})\n\n`;

    // Add scraped date
    markdown += `> ðŸ“… Scraped: ${new Date().toLocaleDateString('en-US', { 
        year: 'numeric', 
        month: 'long', 
        day: 'numeric' 
    })}\n\n`;

    markdown += '---\n\n';

    // Convert HTML content to Markdown
    if (data.html) {
        const converted = turndownService.turndown(data.html);
        markdown += converted + '\n\n';
    }

    // Optionally list extracted images at the end of the note
    if (data._images && data._images.length > 0) {
        markdown += '\n---\n\n';
        markdown += '## Images\n\n';
        for (const img of data._images) {
            markdown += `- ![${img.alt || ''}](${img.src})` + '\n';
        }
        markdown += '\n';
    }

    // Add metadata section at the bottom
    if (data.metadata.description || data.metadata.author) {
        markdown += '\n---\n\n';
        markdown += '## Metadata\n\n';
        if (data.metadata.author) {
            markdown += `- **Author:** ${data.metadata.author}\n`;
        }
        if (data.metadata.description) {
            markdown += `- **Description:** ${data.metadata.description}\n`;
        }
    }

    return markdown;
}

/**
 * Save markdown content to Obsidian vault
 */
async function saveToVault(vaultPath, folderPath, fileName, content) {
    const fullFolderPath = path.join(vaultPath, folderPath);
    const fullFilePath = path.join(fullFolderPath, `${fileName}.md`);

    // Create folder if it doesn't exist
    await fs.mkdir(fullFolderPath, { recursive: true });

    // Write the markdown file
    await fs.writeFile(fullFilePath, content, 'utf8');
}
